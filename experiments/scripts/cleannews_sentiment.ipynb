{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8f5182f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from torch.nn.functional import softmax\n",
    "import torch.nn.functional as F\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "94acef5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "hdfc_file_path = r'F:\\Xai_traderx\\data\\raw\\HDFC_news_21.csv'\n",
    "reliance_file_path = r'F:\\Xai_traderx\\data\\raw\\Reliance_news_21.csv'\n",
    "\n",
    "# save the path after sentiment adding\n",
    "hdfc_output_path = r'F:\\Xai_traderx\\data\\processed\\HDFC_news_sentiment_summary.csv'\n",
    "reliance_output_path = r'F:\\Xai_traderx\\data\\processed\\Reliance_news_sentiment_summary.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "20be4614",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HDFC:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "      <th>date</th>\n",
       "      <th>link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Asian Equities Traded in the US as American De...</td>\n",
       "      <td>08:07:25 29/04/2025 pm IST</td>\n",
       "      <td>/quote/stock/VNET-GROUP-INC-7855123/news/Asian...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Asian Equities Traded in the US as American De...</td>\n",
       "      <td>08:10:13 28/04/2025 pm IST</td>\n",
       "      <td>/quote/stock/SIFY-TECHNOLOGIES-LIMITED-10829/n...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            headline  \\\n",
       "0  Asian Equities Traded in the US as American De...   \n",
       "1  Asian Equities Traded in the US as American De...   \n",
       "\n",
       "                         date  \\\n",
       "0  08:07:25 29/04/2025 pm IST   \n",
       "1  08:10:13 28/04/2025 pm IST   \n",
       "\n",
       "                                                link  \n",
       "0  /quote/stock/VNET-GROUP-INC-7855123/news/Asian...  \n",
       "1  /quote/stock/SIFY-TECHNOLOGIES-LIMITED-10829/n...  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hdfc_df = pd.read_csv(hdfc_file_path)\n",
    "reliance_df = pd.read_csv(reliance_file_path)\n",
    "print(\"HDFC:\")\n",
    "hdfc_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2449b56b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reliance:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "      <th>date</th>\n",
       "      <th>link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INDIA STOCKS-Indian benchmarks surrender gains...</td>\n",
       "      <td>03:41:15 29/04/2025 pm IST</td>\n",
       "      <td>/quote/index/SENSEX-BSE30-7426/news/INDIA-STOC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>INDIA STOCKS-Indian stocks gain on foreign inv...</td>\n",
       "      <td>10:08:24 29/04/2025 am IST</td>\n",
       "      <td>/quote/index/SENSEX-BSE30-7426/news/INDIA-STOC...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            headline  \\\n",
       "0  INDIA STOCKS-Indian benchmarks surrender gains...   \n",
       "1  INDIA STOCKS-Indian stocks gain on foreign inv...   \n",
       "\n",
       "                         date  \\\n",
       "0  03:41:15 29/04/2025 pm IST   \n",
       "1  10:08:24 29/04/2025 am IST   \n",
       "\n",
       "                                                link  \n",
       "0  /quote/index/SENSEX-BSE30-7426/news/INDIA-STOC...  \n",
       "1  /quote/index/SENSEX-BSE30-7426/news/INDIA-STOC...  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Reliance:\")\n",
    "reliance_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa48f5d7",
   "metadata": {},
   "source": [
    " WE Should Clean Our data first and change date fromat and all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b9c5a412",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_news_date(df):\n",
    "    df['date'] = df['date'].astype(str)\n",
    "    df['date'] = df['date'].str.replace(r'(\\s[apm]+\\sIST)', '', regex=True)\n",
    "    df['date'] = pd.to_datetime(df['date'], errors='coerce')\n",
    "    df['date'] = df['date'].dt.date\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770acf49",
   "metadata": {},
   "source": [
    " We found that there is duplicates news headline per day to solve that we add function that remove duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0de29d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_daily_duplicates(df):\n",
    "    df = df.drop_duplicates(subset=['date', 'headline'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dca34bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load FinBERT model and tokenizer\n",
    "def load_finbert_model():\n",
    "    model_name = \"yiyanghkust/finbert-tone\"\n",
    "    tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "    model = BertForSequenceClassification.from_pretrained(model_name)\n",
    "    return tokenizer, model\n",
    "\n",
    "\n",
    "def sentiment_analysis_with_scores(df, tokenizer, model):\n",
    "    sentiment_labels = []\n",
    "    polarity_scores = []  # Renamed from sentiment_scores to avoid confusion\n",
    "    \n",
    "    for headline in df['headline']:\n",
    "        inputs = tokenizer(headline, return_tensors='pt', truncation=True, padding=True, max_length=512)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "        \n",
    "        # Get probability distribution\n",
    "        probs = F.softmax(outputs.logits, dim=-1).squeeze()  # Shape: [3]\n",
    "        \n",
    "        # Classify (same as before)\n",
    "        label_id = torch.argmax(probs).item()\n",
    "        if label_id == 0:\n",
    "            sentiment_labels.append('Negative')\n",
    "        elif label_id == 1:\n",
    "            sentiment_labels.append('Neutral')\n",
    "        else:\n",
    "            sentiment_labels.append('Positive')\n",
    "        \n",
    "        # Calculate polarity score: Positive prob - Negative prob (range: -1 to +1)\n",
    "        polarity_score = probs[2].item() - probs[0].item()  #\n",
    "        polarity_scores.append(polarity_score)\n",
    "    \n",
    "    df['sentiment_label'] = sentiment_labels\n",
    "    df['sentiment_score'] = polarity_scores  \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a7da6515",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_sentiment(df):\n",
    "    summary = df.groupby('date').agg(\n",
    "        positive_count=('sentiment_label', lambda x: (x == 'Positive').sum()),\n",
    "        negative_count=('sentiment_label', lambda x: (x == 'Negative').sum()),\n",
    "        neutral_count=('sentiment_label', lambda x: (x == 'Neutral').sum()),\n",
    "        avg_sentiment_score=('sentiment_score', 'mean')\n",
    "    ).reset_index()\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3330efaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shahe\\AppData\\Local\\Temp\\ipykernel_20188\\65328465.py:4: UserWarning: Parsing dates in %H:%M:%S %d/%m/%Y format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  df['date'] = pd.to_datetime(df['date'], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Processed sentiment summary saved to: F:\\Xai_traderx\\data\\processed\\HDFC_news_sentiment_summary.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shahe\\AppData\\Local\\Temp\\ipykernel_20188\\65328465.py:4: UserWarning: Parsing dates in %H:%M:%S %d/%m/%Y format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  df['date'] = pd.to_datetime(df['date'], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Processed sentiment summary saved to: F:\\Xai_traderx\\data\\processed\\Reliance_news_sentiment_summary.csv\n"
     ]
    }
   ],
   "source": [
    "### Applying the pipline \n",
    "def process_news(file_path, output_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "    df = clean_news_date(df)\n",
    "\n",
    "    tokenizer, model = load_finbert_model()\n",
    "    df = sentiment_analysis_with_scores(df, tokenizer, model)\n",
    "\n",
    "    summary_df = summarize_sentiment(df)\n",
    "    summary_df.to_csv(output_path, index=False)\n",
    "    print(f\"✅ Processed sentiment summary saved to: {output_path}\")\n",
    "\n",
    "# calling the function \n",
    "process_news(hdfc_file_path, hdfc_output_path)\n",
    "process_news(reliance_file_path, reliance_output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9799a04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ba7fa5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xaitrade",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
