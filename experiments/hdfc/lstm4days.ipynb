{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb6fc3d6",
   "metadata": {},
   "source": [
    "### First we have trying the same approch that done in Relince stock "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b1a0b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout,Input\n",
    "from tensorflow.keras.optimizers import Nadam\n",
    "from tensorflow.keras.losses import Huber\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e95f176",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>Close</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Volume</th>\n",
       "      <th>positive_count</th>\n",
       "      <th>negative_count</th>\n",
       "      <th>neutral_count</th>\n",
       "      <th>avg_sentiment_score</th>\n",
       "      <th>...</th>\n",
       "      <th>SMA_50</th>\n",
       "      <th>EMA_10</th>\n",
       "      <th>EMA_50</th>\n",
       "      <th>EMA_12</th>\n",
       "      <th>EMA_26</th>\n",
       "      <th>RSI_14</th>\n",
       "      <th>MACD</th>\n",
       "      <th>Signal</th>\n",
       "      <th>Volatility</th>\n",
       "      <th>Momentum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-08-24</td>\n",
       "      <td>1072.344238</td>\n",
       "      <td>1078.008019</td>\n",
       "      <td>1042.200884</td>\n",
       "      <td>1042.536853</td>\n",
       "      <td>18389870</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-6.667675e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>1048.585562</td>\n",
       "      <td>1025.204099</td>\n",
       "      <td>1054.382459</td>\n",
       "      <td>1023.134182</td>\n",
       "      <td>1024.227997</td>\n",
       "      <td>48.475442</td>\n",
       "      <td>-1.093815</td>\n",
       "      <td>-9.214172</td>\n",
       "      <td>32.736386</td>\n",
       "      <td>79.294434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-08-28</td>\n",
       "      <td>1069.896118</td>\n",
       "      <td>1079.975893</td>\n",
       "      <td>1051.176536</td>\n",
       "      <td>1067.448126</td>\n",
       "      <td>19348305</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-9.998460e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>1045.239075</td>\n",
       "      <td>1033.329920</td>\n",
       "      <td>1054.990838</td>\n",
       "      <td>1030.328326</td>\n",
       "      <td>1027.610821</td>\n",
       "      <td>49.234122</td>\n",
       "      <td>2.717505</td>\n",
       "      <td>-6.827837</td>\n",
       "      <td>32.122416</td>\n",
       "      <td>78.478271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-08-31</td>\n",
       "      <td>1071.192139</td>\n",
       "      <td>1102.823505</td>\n",
       "      <td>1056.648439</td>\n",
       "      <td>1084.295871</td>\n",
       "      <td>19250583</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-6.124693e-08</td>\n",
       "      <td>...</td>\n",
       "      <td>1042.459937</td>\n",
       "      <td>1040.213960</td>\n",
       "      <td>1055.626183</td>\n",
       "      <td>1036.615066</td>\n",
       "      <td>1030.839067</td>\n",
       "      <td>56.935701</td>\n",
       "      <td>5.776000</td>\n",
       "      <td>-4.307070</td>\n",
       "      <td>35.243832</td>\n",
       "      <td>47.279053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-09-02</td>\n",
       "      <td>1088.759644</td>\n",
       "      <td>1093.415516</td>\n",
       "      <td>1075.847862</td>\n",
       "      <td>1079.111813</td>\n",
       "      <td>9880841</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-9.995025e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>1039.477285</td>\n",
       "      <td>1049.040448</td>\n",
       "      <td>1056.925535</td>\n",
       "      <td>1044.637309</td>\n",
       "      <td>1035.129480</td>\n",
       "      <td>71.688395</td>\n",
       "      <td>9.507829</td>\n",
       "      <td>-1.544090</td>\n",
       "      <td>39.417105</td>\n",
       "      <td>72.142273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-09-04</td>\n",
       "      <td>1074.504028</td>\n",
       "      <td>1080.359874</td>\n",
       "      <td>1060.200325</td>\n",
       "      <td>1065.576181</td>\n",
       "      <td>11830685</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.826069e-03</td>\n",
       "      <td>...</td>\n",
       "      <td>1036.873823</td>\n",
       "      <td>1053.670190</td>\n",
       "      <td>1057.614887</td>\n",
       "      <td>1049.232189</td>\n",
       "      <td>1038.046113</td>\n",
       "      <td>76.940728</td>\n",
       "      <td>11.186076</td>\n",
       "      <td>1.001943</td>\n",
       "      <td>37.481521</td>\n",
       "      <td>32.303223</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         date        Close         High          Low         Open    Volume  \\\n",
       "0  2020-08-24  1072.344238  1078.008019  1042.200884  1042.536853  18389870   \n",
       "1  2020-08-28  1069.896118  1079.975893  1051.176536  1067.448126  19348305   \n",
       "2  2020-08-31  1071.192139  1102.823505  1056.648439  1084.295871  19250583   \n",
       "3  2020-09-02  1088.759644  1093.415516  1075.847862  1079.111813   9880841   \n",
       "4  2020-09-04  1074.504028  1080.359874  1060.200325  1065.576181  11830685   \n",
       "\n",
       "   positive_count  negative_count  neutral_count  avg_sentiment_score  ...  \\\n",
       "0             0.0             2.0            1.0        -6.667675e-01  ...   \n",
       "1             0.0             2.0            0.0        -9.998460e-01  ...   \n",
       "2             0.0             0.0            1.0        -6.124693e-08  ...   \n",
       "3             0.0             1.0            0.0        -9.995025e-01  ...   \n",
       "4             1.0             1.0            0.0         8.826069e-03  ...   \n",
       "\n",
       "        SMA_50       EMA_10       EMA_50       EMA_12       EMA_26     RSI_14  \\\n",
       "0  1048.585562  1025.204099  1054.382459  1023.134182  1024.227997  48.475442   \n",
       "1  1045.239075  1033.329920  1054.990838  1030.328326  1027.610821  49.234122   \n",
       "2  1042.459937  1040.213960  1055.626183  1036.615066  1030.839067  56.935701   \n",
       "3  1039.477285  1049.040448  1056.925535  1044.637309  1035.129480  71.688395   \n",
       "4  1036.873823  1053.670190  1057.614887  1049.232189  1038.046113  76.940728   \n",
       "\n",
       "        MACD    Signal  Volatility   Momentum  \n",
       "0  -1.093815 -9.214172   32.736386  79.294434  \n",
       "1   2.717505 -6.827837   32.122416  78.478271  \n",
       "2   5.776000 -4.307070   35.243832  47.279053  \n",
       "3   9.507829 -1.544090   39.417105  72.142273  \n",
       "4  11.186076  1.001943   37.481521  32.303223  \n",
       "\n",
       "[5 rows x 50 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = r\"F:\\Xai_traderx\\experiments\\hdfc\\hdfcdemo.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98b3d21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = [\n",
    "    # Price Action\n",
    "    'Close', 'High', 'Low', 'Open',\n",
    "    \n",
    "    # Short-Term Trends\n",
    "    'SMA_7', 'SMA_10', 'EMA_10',\n",
    "    \n",
    "    # Volatility & Volume\n",
    "    'bb_upper', 'bb_lower', 'OBV', 'ATR',\n",
    "    \n",
    "    # Optional (Test Impact)\n",
    "    'EMA_50', 'RSI_14', 'MACD_Hist'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f987e525",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_selected = df[selected_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63529e31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train_seq: (746, 4, 14)\n",
      "Shape of y_train_seq: (746, 1)\n",
      "Shape of X_test_seq: (184, 4, 14)\n",
      "Shape of y_test_seq: (184, 1)\n"
     ]
    }
   ],
   "source": [
    "# 1. Separate features and target\n",
    "features = df_selected\n",
    "target = df[['next_close']]\n",
    "\n",
    "# 2. Scale features and target separately\n",
    "scaler_X = MinMaxScaler()\n",
    "X_scaled = scaler_X.fit_transform(features)\n",
    "\n",
    "scaler_y = MinMaxScaler()\n",
    "y_scaled = scaler_y.fit_transform(target)\n",
    "\n",
    "# 3. Train-test split (no shuffle)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_scaled, shuffle=False, test_size=0.2)\n",
    "\n",
    "# 4. Define lookback\n",
    "lookback = 4\n",
    "\n",
    "# 5. Sequence creation function\n",
    "def create_sequence(X, y, lookback):\n",
    "    Xs, ys = [], []\n",
    "    for i in range(len(X) - lookback):\n",
    "        Xs.append(X[i:(i + lookback)])\n",
    "        ys.append(y[i + lookback])\n",
    "    return np.array(Xs), np.array(ys)\n",
    "\n",
    "# 6. Create sequences\n",
    "X_train_seq, y_train_seq = create_sequence(X_train, y_train, lookback)\n",
    "X_test_seq, y_test_seq = create_sequence(X_test, y_test, lookback)\n",
    "\n",
    "print(\"Shape of X_train_seq:\", X_train_seq.shape)\n",
    "print(\"Shape of y_train_seq:\", y_train_seq.shape)\n",
    "print(\"Shape of X_test_seq:\", X_test_seq.shape)\n",
    "print(\"Shape of y_test_seq:\", y_test_seq.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a9858dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Input(shape=(lookback, X_train_seq.shape[2])), \n",
    "    LSTM(100, return_sequences=True),  # LSTM layer 1\n",
    "    Dropout(0.2),  # Dropout for regularization\n",
    "    LSTM(100, return_sequences=False),  # LSTM layer 2\n",
    "    Dropout(0.2),  # Dropout for regularization\n",
    "    Dense(1)  # Output layer (predicts Next_Close)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5cb0f892",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Nadam(learning_rate=1e-4)\n",
    "model.compile(optimizer=optimizer, loss=Huber(), metrics=['mae'])\n",
    "\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_mae', patience=50, restore_best_weights=True),\n",
    "    ModelCheckpoint('lstm4dayhdfc.keras', save_best_only=True),\n",
    "    ReduceLROnPlateau(monitor='val_mae', factor=0.5, patience=25, min_lr=1e-6)  # Learning rate adjustment\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "92f6b3cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "\u001b[1m746/746\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - loss: 0.0026 - mae: 0.0575 - val_loss: 0.0084 - val_mae: 0.1165 - learning_rate: 1.0000e-04\n",
      "Epoch 2/500\n",
      "\u001b[1m746/746\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 0.0027 - mae: 0.0553 - val_loss: 0.0081 - val_mae: 0.1117 - learning_rate: 1.0000e-04\n",
      "Epoch 3/500\n",
      "\u001b[1m746/746\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 0.0029 - mae: 0.0573 - val_loss: 0.0090 - val_mae: 0.1180 - learning_rate: 1.0000e-04\n",
      "Epoch 4/500\n",
      "\u001b[1m746/746\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 0.0030 - mae: 0.0568 - val_loss: 0.0140 - val_mae: 0.1531 - learning_rate: 1.0000e-04\n",
      "Epoch 5/500\n",
      "\u001b[1m746/746\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 0.0027 - mae: 0.0560 - val_loss: 0.0139 - val_mae: 0.1515 - learning_rate: 1.0000e-04\n",
      "Epoch 6/500\n",
      "\u001b[1m746/746\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 0.0026 - mae: 0.0553 - val_loss: 0.0154 - val_mae: 0.1596 - learning_rate: 1.0000e-04\n",
      "Epoch 7/500\n",
      "\u001b[1m746/746\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 0.0029 - mae: 0.0558 - val_loss: 0.0166 - val_mae: 0.1670 - learning_rate: 1.0000e-04\n",
      "Epoch 8/500\n",
      "\u001b[1m746/746\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 0.0028 - mae: 0.0550 - val_loss: 0.0150 - val_mae: 0.1572 - learning_rate: 1.0000e-04\n",
      "Epoch 9/500\n",
      "\u001b[1m746/746\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 0.0025 - mae: 0.0526 - val_loss: 0.0196 - val_mae: 0.1837 - learning_rate: 1.0000e-04\n",
      "Epoch 10/500\n",
      "\u001b[1m746/746\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 0.0022 - mae: 0.0503 - val_loss: 0.0195 - val_mae: 0.1824 - learning_rate: 1.0000e-04\n",
      "Epoch 11/500\n",
      "\u001b[1m746/746\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 0.0024 - mae: 0.0515 - val_loss: 0.0183 - val_mae: 0.1757 - learning_rate: 1.0000e-04\n",
      "Epoch 12/500\n",
      "\u001b[1m746/746\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 0.0022 - mae: 0.0501 - val_loss: 0.0191 - val_mae: 0.1800 - learning_rate: 1.0000e-04\n",
      "Epoch 13/500\n",
      "\u001b[1m746/746\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 0.0019 - mae: 0.0469 - val_loss: 0.0230 - val_mae: 0.1998 - learning_rate: 1.0000e-04\n",
      "Epoch 14/500\n",
      "\u001b[1m746/746\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 0.0018 - mae: 0.0455 - val_loss: 0.0251 - val_mae: 0.2094 - learning_rate: 1.0000e-04\n",
      "Epoch 15/500\n",
      "\u001b[1m746/746\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 0.0016 - mae: 0.0451 - val_loss: 0.0276 - val_mae: 0.2204 - learning_rate: 1.0000e-04\n",
      "Epoch 16/500\n",
      "\u001b[1m746/746\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 0.0017 - mae: 0.0452 - val_loss: 0.0261 - val_mae: 0.2133 - learning_rate: 1.0000e-04\n",
      "Epoch 17/500\n",
      "\u001b[1m746/746\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 0.0016 - mae: 0.0445 - val_loss: 0.0279 - val_mae: 0.2216 - learning_rate: 1.0000e-04\n",
      "Epoch 18/500\n",
      "\u001b[1m746/746\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 0.0016 - mae: 0.0450 - val_loss: 0.0294 - val_mae: 0.2279 - learning_rate: 1.0000e-04\n",
      "Epoch 19/500\n",
      "\u001b[1m746/746\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 0.0015 - mae: 0.0428 - val_loss: 0.0290 - val_mae: 0.2256 - learning_rate: 1.0000e-04\n",
      "Epoch 20/500\n",
      "\u001b[1m746/746\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 0.0015 - mae: 0.0445 - val_loss: 0.0294 - val_mae: 0.2269 - learning_rate: 1.0000e-04\n",
      "Epoch 21/500\n",
      "\u001b[1m746/746\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 0.0015 - mae: 0.0418 - val_loss: 0.0302 - val_mae: 0.2303 - learning_rate: 1.0000e-04\n",
      "Epoch 22/500\n",
      "\u001b[1m746/746\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 0.0013 - mae: 0.0392 - val_loss: 0.0308 - val_mae: 0.2336 - learning_rate: 1.0000e-04\n",
      "Epoch 23/500\n",
      "\u001b[1m746/746\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 0.0012 - mae: 0.0386 - val_loss: 0.0303 - val_mae: 0.2313 - learning_rate: 1.0000e-04\n",
      "Epoch 24/500\n",
      "\u001b[1m746/746\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 0.0013 - mae: 0.0398 - val_loss: 0.0307 - val_mae: 0.2328 - learning_rate: 1.0000e-04\n",
      "Epoch 25/500\n",
      "\u001b[1m746/746\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 0.0013 - mae: 0.0394 - val_loss: 0.0317 - val_mae: 0.2366 - learning_rate: 1.0000e-04\n",
      "Epoch 26/500\n",
      "\u001b[1m746/746\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 0.0013 - mae: 0.0400 - val_loss: 0.0319 - val_mae: 0.2373 - learning_rate: 1.0000e-04\n",
      "Epoch 27/500\n",
      "\u001b[1m746/746\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 0.0014 - mae: 0.0405 - val_loss: 0.0314 - val_mae: 0.2355 - learning_rate: 1.0000e-04\n",
      "Epoch 28/500\n",
      "\u001b[1m746/746\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 0.0015 - mae: 0.0429 - val_loss: 0.0230 - val_mae: 0.1990 - learning_rate: 5.0000e-05\n",
      "Epoch 29/500\n",
      "\u001b[1m746/746\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 0.0014 - mae: 0.0420 - val_loss: 0.0214 - val_mae: 0.1912 - learning_rate: 5.0000e-05\n",
      "Epoch 30/500\n",
      "\u001b[1m746/746\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 0.0012 - mae: 0.0392 - val_loss: 0.0210 - val_mae: 0.1901 - learning_rate: 5.0000e-05\n",
      "Epoch 31/500\n",
      "\u001b[1m746/746\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 0.0012 - mae: 0.0382 - val_loss: 0.0191 - val_mae: 0.1802 - learning_rate: 5.0000e-05\n",
      "Epoch 32/500\n",
      "\u001b[1m746/746\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 0.0012 - mae: 0.0388 - val_loss: 0.0212 - val_mae: 0.1915 - learning_rate: 5.0000e-05\n",
      "Epoch 33/500\n",
      "\u001b[1m746/746\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 0.0012 - mae: 0.0380 - val_loss: 0.0191 - val_mae: 0.1806 - learning_rate: 5.0000e-05\n",
      "Epoch 34/500\n",
      "\u001b[1m746/746\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 0.0012 - mae: 0.0381 - val_loss: 0.0194 - val_mae: 0.1821 - learning_rate: 5.0000e-05\n",
      "Epoch 35/500\n",
      "\u001b[1m746/746\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - loss: 0.0012 - mae: 0.0376 - val_loss: 0.0183 - val_mae: 0.1765 - learning_rate: 5.0000e-05\n",
      "Epoch 36/500\n",
      "\u001b[1m746/746\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 0.0012 - mae: 0.0387 - val_loss: 0.0189 - val_mae: 0.1799 - learning_rate: 5.0000e-05\n",
      "Epoch 37/500\n",
      "\u001b[1m746/746\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 0.0012 - mae: 0.0399 - val_loss: 0.0188 - val_mae: 0.1790 - learning_rate: 5.0000e-05\n",
      "Epoch 38/500\n",
      "\u001b[1m746/746\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 0.0012 - mae: 0.0375 - val_loss: 0.0183 - val_mae: 0.1766 - learning_rate: 5.0000e-05\n",
      "Epoch 39/500\n",
      "\u001b[1m746/746\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 0.0011 - mae: 0.0369 - val_loss: 0.0181 - val_mae: 0.1757 - learning_rate: 5.0000e-05\n",
      "Epoch 40/500\n",
      "\u001b[1m746/746\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 0.0011 - mae: 0.0375 - val_loss: 0.0192 - val_mae: 0.1816 - learning_rate: 5.0000e-05\n",
      "Epoch 41/500\n",
      "\u001b[1m746/746\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 0.0012 - mae: 0.0372 - val_loss: 0.0175 - val_mae: 0.1723 - learning_rate: 5.0000e-05\n",
      "Epoch 42/500\n",
      "\u001b[1m746/746\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 0.0011 - mae: 0.0366 - val_loss: 0.0175 - val_mae: 0.1723 - learning_rate: 5.0000e-05\n",
      "Epoch 43/500\n",
      "\u001b[1m746/746\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 0.0011 - mae: 0.0369 - val_loss: 0.0167 - val_mae: 0.1685 - learning_rate: 5.0000e-05\n",
      "Epoch 44/500\n",
      "\u001b[1m746/746\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 0.0012 - mae: 0.0382 - val_loss: 0.0183 - val_mae: 0.1769 - learning_rate: 5.0000e-05\n",
      "Epoch 45/500\n",
      "\u001b[1m746/746\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 0.0011 - mae: 0.0366 - val_loss: 0.0181 - val_mae: 0.1760 - learning_rate: 5.0000e-05\n",
      "Epoch 46/500\n",
      "\u001b[1m746/746\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 0.0012 - mae: 0.0373 - val_loss: 0.0163 - val_mae: 0.1660 - learning_rate: 5.0000e-05\n",
      "Epoch 47/500\n",
      "\u001b[1m746/746\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 0.0011 - mae: 0.0370 - val_loss: 0.0178 - val_mae: 0.1748 - learning_rate: 5.0000e-05\n",
      "Epoch 48/500\n",
      "\u001b[1m746/746\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 0.0011 - mae: 0.0363 - val_loss: 0.0175 - val_mae: 0.1727 - learning_rate: 5.0000e-05\n",
      "Epoch 49/500\n",
      "\u001b[1m746/746\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 0.0011 - mae: 0.0378 - val_loss: 0.0171 - val_mae: 0.1702 - learning_rate: 5.0000e-05\n",
      "Epoch 50/500\n",
      "\u001b[1m746/746\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 0.0011 - mae: 0.0373 - val_loss: 0.0158 - val_mae: 0.1629 - learning_rate: 5.0000e-05\n",
      "Epoch 51/500\n",
      "\u001b[1m746/746\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 0.0011 - mae: 0.0368 - val_loss: 0.0164 - val_mae: 0.1667 - learning_rate: 5.0000e-05\n",
      "Epoch 52/500\n",
      "\u001b[1m746/746\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 0.0011 - mae: 0.0374 - val_loss: 0.0177 - val_mae: 0.1743 - learning_rate: 5.0000e-05\n",
      "Training Completed..\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train_seq, y_train_seq,\n",
    "    validation_data=(X_test_seq, y_test_seq),\n",
    "    epochs=500,\n",
    "    batch_size=1,\n",
    "    callbacks=callbacks,\n",
    "    shuffle=False,  # Keep the order of time series data\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"Training Completed..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cb4ca40a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0058 - mae: 0.0927 \n",
      "Test Loss: 0.008121890015900135\n",
      "Test MAE: 0.11172332614660263\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_mae = model.evaluate(X_test_seq, y_test_seq)\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "print(f\"Test MAE: {test_mae}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "819e8609",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred_scaled = model.predict(X_test_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c333f7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape if needed\n",
    "y_pred_scaled = y_pred_scaled.reshape(-1, 1)\n",
    "y_test_seq = y_test_seq.reshape(-1, 1)\n",
    "\n",
    "# Inverse transform\n",
    "y_pred = scaler_y.inverse_transform(y_pred_scaled)\n",
    "y_true = scaler_y.inverse_transform(y_test_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1ec3a48b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 108.1189\n",
      "RMSE: 123.3393\n",
      "R2 Score: -0.8429\n",
      "Percentage Error: 6.33%\n"
     ]
    }
   ],
   "source": [
    "mae = mean_absolute_error(y_true, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "r2 = r2_score(y_true, y_pred)\n",
    "percentage_error = (mae / np.mean(y_true)) * 100\n",
    "print(f\"MAE: {mae:.4f}\")\n",
    "print(f\"RMSE: {rmse:.4f}\")\n",
    "print(f\"R2 Score: {r2:.4f}\")\n",
    "print(f\"Percentage Error: {percentage_error:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "309ed755",
   "metadata": {},
   "source": [
    "The RMSE and MAE are higher than expected, which means  model struggles to accurately predict the next day's price for HDFC stock."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec092e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xaitrade",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
